{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T19:15:53.511789Z",
     "start_time": "2026-02-16T19:15:53.400492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_csv_with_analysis(file_path: str, delimiter: str = ','):\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Å –ø–æ–ª–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "    Args:\n",
    "        file_path: –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É\n",
    "        delimiter: —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ',')\n",
    "    \"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞\n",
    "    if not Path(file_path).exists():\n",
    "        print(f\"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            delimiter=delimiter,\n",
    "            encoding='utf-8',\n",
    "            skipinitialspace=True,  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è\n",
    "            na_values=['', 'NA', 'N/A', 'null', 'NULL', 'NaN', 'None'],  # –î–æ–ø. –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "            keep_default_na=True\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {file_path}\")\n",
    "        print(f\"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
    "        print(f\"üìã –°—Ç–æ–ª–±—Ü—ã: {'|'.join(df.columns)}\")\n",
    "\n",
    "        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"üìä –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        missing_count = df.isnull().sum()\n",
    "        missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "        missing_df = pd.DataFrame({\n",
    "            '–ö–æ–ª–æ–Ω–∫–∞': df.columns,\n",
    "            '–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫': len(df),\n",
    "            '–ü—Ä–æ–ø—É—â–µ–Ω–æ': missing_count.values,\n",
    "            '–ó–∞–ø–æ–ª–Ω–µ–Ω–æ': len(df) - missing_count.values,\n",
    "            '% –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_percent.values,\n",
    "            '–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö': df.dtypes.values\n",
    "        })\n",
    "\n",
    "        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "        missing_df = missing_df.sort_values('–ü—Ä–æ–ø—É—â–µ–Ω–æ', ascending=False)\n",
    "\n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        for idx, row in missing_df.iterrows():\n",
    "            col = row['–ö–æ–ª–æ–Ω–∫–∞']\n",
    "            missing = row['–ü—Ä–æ–ø—É—â–µ–Ω–æ']\n",
    "            percent = row['% –ø—Ä–æ–ø—É—Å–∫–æ–≤']\n",
    "            data_type = row['–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö']\n",
    "\n",
    "            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω—É—é —à–∫–∞–ª—É\n",
    "            bar_length = 40\n",
    "            filled = int((len(df) - missing) / len(df) * bar_length)\n",
    "            bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "\n",
    "            status = \"‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–ü–û–õ–ù–ï–ù–û\" if missing == 0 else f\"‚ö†Ô∏è  –ø—Ä–æ–ø—É—Å–∫–æ–≤: {missing}\"\n",
    "            print(f\"{col:25} [{bar}] {status} ({percent:.1f}%) [{data_type}]\")\n",
    "\n",
    "        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"üìà –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # –ö–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "        cols_with_missing = missing_df[missing_df['–ü—Ä–æ–ø—É—â–µ–Ω–æ'] > 0]\n",
    "        if not cols_with_missing.empty:\n",
    "            print(f\"\\n‚ùå –°—Ç–æ–ª–±—Ü–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ ({len(cols_with_missing)}):\")\n",
    "            for _, row in cols_with_missing.iterrows():\n",
    "                print(f\"  ‚Ä¢ {row['–ö–æ–ª–æ–Ω–∫–∞']}: {row['–ü—Ä–æ–ø—É—â–µ–Ω–æ']} –ø—Ä–æ–ø—É—Å–∫–æ–≤ ({row['% –ø—Ä–æ–ø—É—Å–∫–æ–≤']:.1f}%)\")\n",
    "\n",
    "        # –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "        cols_full = missing_df[missing_df['–ü—Ä–æ–ø—É—â–µ–Ω–æ'] == 0]\n",
    "        if not cols_full.empty:\n",
    "            print(f\"\\n‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã ({len(cols_full)}):\")\n",
    "            print(f\"  ‚Ä¢ {'|'.join(cols_full['–ö–æ–ª–æ–Ω–∫–∞'].tolist())}\")\n",
    "\n",
    "        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        total_missing = df.isnull().sum().sum()\n",
    "        total_cells = df.size\n",
    "        print(f\"\\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "        print(f\"  ‚Ä¢ –í—Å–µ–≥–æ —è—á–µ–µ–∫: {total_cells}\")\n",
    "        print(f\"  ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: {total_missing}\")\n",
    "        print(f\"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤: {(total_missing / total_cells) * 100:.2f}%\")\n",
    "        print(f\"  ‚Ä¢ –°—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {df.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "        return df, missing_df\n",
    "\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"‚ùå –§–∞–π–ª –ø—É—Å—Ç–æ–π\")\n",
    "        return None\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ CSV: {e}\")\n",
    "        return None\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n",
    "result = load_csv_with_analysis('DatasetSnowSales2.csv', delimiter=';')\n",
    "\n",
    "if result:\n",
    "    df, stats = result\n",
    "\n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∂–µ–ª–∞–Ω–∏—é\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üîç –ü–†–ò–ú–ï–†–´ –î–ê–ù–ù–´–•\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "    print(df.tail())\n",
    "\n",
    "    print(\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º:\")\n",
    "    print(df.describe())"
   ],
   "id": "6317fb96442b5f24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: DatasetSnowSales2.csv\n",
      "üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 74 —Å—Ç—Ä–æ–∫ √ó 6 —Å—Ç–æ–ª–±—Ü–æ–≤\n",
      "üìã –°—Ç–æ–ª–±—Ü—ã: Date|dayweek|sales|tempday|tempnight|precipitation\n",
      "\n",
      "==================================================\n",
      "üìä –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô\n",
      "==================================================\n",
      "sales                     [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] ‚ö†Ô∏è  –ø—Ä–æ–ø—É—Å–∫–æ–≤: 1 (1.4%) [float64]\n",
      "Date                      [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–ü–û–õ–ù–ï–ù–û (0.0%) [object]\n",
      "dayweek                   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–ü–û–õ–ù–ï–ù–û (0.0%) [int64]\n",
      "tempday                   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–ü–û–õ–ù–ï–ù–û (0.0%) [int64]\n",
      "tempnight                 [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–ü–û–õ–ù–ï–ù–û (0.0%) [int64]\n",
      "precipitation             [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–ü–û–õ–ù–ï–ù–û (0.0%) [object]\n",
      "\n",
      "==================================================\n",
      "üìà –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê\n",
      "==================================================\n",
      "\n",
      "‚ùå –°—Ç–æ–ª–±—Ü–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ (1):\n",
      "  ‚Ä¢ sales: 1 –ø—Ä–æ–ø—É—Å–∫–æ–≤ (1.4%)\n",
      "\n",
      "‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (5):\n",
      "  ‚Ä¢ Date|dayweek|tempday|tempnight|precipitation\n",
      "\n",
      "üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n",
      "  ‚Ä¢ –í—Å–µ–≥–æ —è—á–µ–µ–∫: 444\n",
      "  ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: 1\n",
      "  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤: 0.23%\n",
      "  ‚Ä¢ –°—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: 1\n",
      "\n",
      "==================================================\n",
      "üîç –ü–†–ò–ú–ï–†–´ –î–ê–ù–ù–´–•\n",
      "==================================================\n",
      "\n",
      "–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n",
      "         Date  dayweek  sales  tempday  tempnight precipitation\n",
      "0  01.12.2025        1  143.0        2          0         cloud\n",
      "1  02.12.2025        2  152.0        3          0         cloud\n",
      "2  03.12.2025        3  148.0        4          0         cloud\n",
      "3  04.12.2025        4   97.0        6          4          rain\n",
      "4  05.12.2025        5  166.0        7          5         cloud\n",
      "\n",
      "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å—Ç—Ä–æ–∫:\n",
      "          Date  dayweek  sales  tempday  tempnight precipitation\n",
      "69  08.02.2026        7  263.0       -5        -12          snow\n",
      "70  09.02.2026        1  185.0       -9        -23           Sun\n",
      "71  10.02.2026        2  206.0       -6        -24           Sun\n",
      "72  11.02.2026        3  293.0       -2         -6          snow\n",
      "73  12.02.2026        4  303.0        1         -2          snow\n",
      "\n",
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º:\n",
      "         dayweek       sales    tempday  tempnight\n",
      "count  74.000000   73.000000  74.000000  74.000000\n",
      "mean    3.918919  323.000000  -3.202703  -9.378378\n",
      "std     2.005177  133.462229   5.954116   8.784642\n",
      "min     1.000000   97.000000 -14.000000 -29.000000\n",
      "25%     2.000000  201.000000  -8.750000 -16.750000\n",
      "50%     4.000000  342.000000  -2.500000  -8.000000\n",
      "75%     6.000000  420.000000   1.000000  -2.000000\n",
      "max     7.000000  696.000000   9.000000   6.000000\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
